# 任务一

**写在前面**：由于我是大二登，之前也自学过机器学习，所以任务一学习的部分就省去了，还是直接回答问题吧，望理解。

- **1. 什么是机器学习**：按照我的理解，计算机通过数据学习，不断改进以捕捉数据的规律和模式的过程称作机器学习。这种规律和模式可以是一组序列的出现规律，机器学习通过已有序列学会如何预测序列的下一个元素，如学习到数组的通项公式；这种规律和模式也可以是把数据按照不同特征分开，如监督学习中的分类问题和无监督学习中的聚类问题。
- **2. 深度学习(Deep Learning)中的“深度”指的是什么？与传统的机器学习方法相比，它最主要的优势是什么？**：在深度学习中，我们的模型是“神经网络”，所谓“深度”可以看作神经网络的层数。不同于传统的机器学习依赖人工提取数据的特征，深度学习可以自动提取数据的特征并不断改进提取特征的“方法（指调整参数）”。传统的机器学习是人教机器，而深度学习是机器在设定的框架下自己学习。
- **3. 监督学习和无监督学习的核心区别是什么？请各举一个典型任务例子。**：从训练数据的角度上来讲，监督学习和无监督学习的核心区别是有无标签。监督学习的目标是通过对``特征——标签``对的学习最后能够通过给定特征预测对应的标签；而无监督学习的目标是捕获数据的结构，模式等，如为一堆没有标签的数据按照一定的模式，结构划分。监督学习的一个典型案例是猫狗图像分类，模型通过对猫狗图像数据的大量学习，最后可以给定一张猫狗图片进行识别。
- **4. 什么是过拟合(Overfitting)？导致过拟合的常见原因有哪些？有哪些手段可以防止或减轻过拟合？**：过拟合指的是模型在训练数据上表现很好甚至完美，与在未见过的数据上的表现差别很大的现象。产生过拟合一般是因为模型过度学习了训练数据中的细节和噪声。具体来说可能是因为模型的表达能力过强，数据样本太少，噪声太大，训练的迭代次数过多等原因。防止或减轻过拟合的手段包括但不限于扩大数据量，在数据不足时使用数据增强手段，降低模型复杂度，使用dropout,使用预训练，使用正则化手段等。
- **5. 什么是欠拟合(Underfitting)？如何改善欠拟合的模型？**: 欠拟合指的是当一个机器学习模型过于简单时不能捕捉到训练数据中的规律特征的现象。改善欠拟合的模型可以采用增加模型深度，从线性模型切换到非线性模型（加入激活函数），减少正则化等方法。
- **6. 请解释偏差(Bias)和方差(Variance)的概念，并阐述它们与过拟合、欠拟合之间的关系（即偏差-方差权衡）**：偏差是用于评价模型学习效果（相当于训练集上的表现）的量，方差是用于评价模型的敏感程度（模型在不同组数据如训练集和测试集上表现的差异）的量。欠拟合的模型往往是高偏差，低方差的，因为它的表达能力不足，在不同数据集上的效果相当；过拟合往往是高方差，低偏差的，因为模型的表达能力过强，使其能记住一些不重要的信息和噪声。偏差和方差成负相关，不能同时最小化，因此会存在偏差-方差权衡。
- **7. 损失函数(Loss Function)的作用是什么？均方误差(MSE)和交叉熵损失(Cross-Entropy Loss)分别适用于什么类型的任务？**：损失函数是用于评估模型的输出与真实值偏差的量，能够体现模型的学习效果。在学习过程中，我们以最小化损失函数为目的进行梯度下降，使参数朝着使损失函数最小的点移动。MSE适用于回归任务，Cross-EntropyLoss适用于分类任务。
- **8. 什么是神经网络的隐藏层**：让我们从最简单的神经网络——线性模型聊起。线性模型由一个从输入到输出的全连接层组成，它的所有表达能力都取决于这一层。显然，这样的表达能力对很多机器学习任务是不够的，那怎么办呢？添加隐藏层，于是有了MLP（多层感知机）。隐藏层因为不与数据直接接触所以称为隐藏层。如向隐藏层中添加激活函数可以让线性模型变成非线性模型，在隐藏层里添加卷积层，池化层可以使模型能够处理具有空间结构的数据等，隐藏层是模型功能和表达能力的集中体现，有着举足轻重的作用。
- **9. 什么是激活函数？它在神经网络中扮演什么角色？常见的激活函数有哪些？**：关于什么是激活函数，我想借用《深度学习中的数学》中的观点。以神经元类比：若一个神经元接受到了刺激，它不一定会向下一个神经元传递信号，而是在信号的强度高于一定的阈值时才会传递信号。这是有益的，不然连一只螨虫在身上爬都能感受到的话我就不能心平气和的打字了。这里用阈值判断信号是否传递的过程可以抽象为一个阶跃函数，当信号强度小于阈值时，就不传递信号；反之，传递信号。这个过程中，阶跃函数用于判断是否激活传递信号，于是被称为激活函数。激活函数可以用于决定上一步的信息向下一步能传递多少。此外，激活函数还为神经网络添加了非线性性。根据某个神奇的逼近定理，有了线性层和激活函数，就可以使神经网络具有逼近任意复杂非线性函数的能力。常见的激活函数有阶跃函数，sigmoid函数，ReLU函数，tanh函数。
- **10. 请描述梯度下降(Gradient Descent)算法的工作原理。它的目标是什么？**：梯度下降算法来自于这样一个特性：梯度方向是函数变化最快的方向。沿着负梯度方向移动能使函数上的点以最快的速度向使函数最小处移动。梯度下降算法的原理是每次计算函数后，更新向梯度负方向以一定步幅移动变量，最终使变量移动至使函数最小的点。它的目标是找到使函数最小的点。在深度学习中，函数指损失函数，变量指参数，我们的目标是找到一组参数使损失函数最小。
- **11. 什么是学习率(Learning Rate)？学习率设置得太大或太小分别会导致什么问题？**：在``问题11``中，我们提到在使用梯度下降时会让变量朝着负梯度方向以一定的步幅移动，这里的步幅便是学习率。当学习率设置过大时，损失函数值会产生震荡，并可能找不到最优解；当学习率设置过小时，损失函数收敛速度慢，且容易陷入局部最优。
- **12. 训练集(Training Set)、验证集(Validation Set)和测试集(Test Set)分别用于什么目的？为什么不能使用训练数据来评估模型的最终性能？**：训练集是模型学习的样本，相当于学生的教材和练习册；验证集是检验模型阶段性学习结果的数据，有利于超参数的调节和监控过拟合是否发生；测试集是评估最终模型的训练效果的数据。为什么不能使用训练数据来评估模型的最终性能？因为一般模型会对训练数据有过拟合，而且这样进行评估不能体现出模型的泛化性。
- **13. 对于分类任务，准确率(Accuracy)、精确率(Precision)、召回率(Recall)分别衡量的是模型的什么能力？**：准确率指的是模型模型整体预测正确的数量，衡量模型对所有样本的总体分类正确程度；精确率是指预测是某个类的数据中真的是这个类的数量，衡量模型对特定类的预测的精确程度；召回率衡量模型对所有实际正类样本的覆盖能力，即模型能找回多少真正的正类。
- **14. 什么是神经网络(Neural Network)？请描述一个最简单的神经网络（单层感知机）是如何工作的。**：神经网络是类比生物的神经系统得到的概念，由大量结构简单的“神经元”节点和它们之间带权重的连接组成。每个神经元接收前一层节点的输入，加权求和后通过非线性激活函数输出信号，层与层之间的信息传递和权重调整使网络能够逼近复杂的函数映射。对于一个最简单的单层感知机，首先将输入乘以权重矩阵，然后加上偏置，然后经过激活函数得到输出。

**写在最后**：我本来以为回答这些问题会很简单，结果还是学到了一些新东西😁

